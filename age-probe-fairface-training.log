[OK] Loading MobileFaceNet...

[OK] Extracting embeddings from FairFace...
[OK] Found 4 training parquet files
[OK] Processing train-00000-of-00004-e715178553977907.parquet...
    Loaded 21686 samples
[OK] Processed 100 images (age bin 3 -> 24.5y)
[OK] Processed 200 images (age bin 2 -> 14.5y)
[OK] Processed 300 images (age bin 1 -> 6.0y)
[OK] Processed 400 images (age bin 3 -> 24.5y)
[OK] Processed 500 images (age bin 5 -> 44.5y)
[OK] Processed 600 images (age bin 3 -> 24.5y)
[OK] Processed 700 images (age bin 4 -> 34.5y)
[OK] Processed 800 images (age bin 1 -> 6.0y)
[OK] Processed 900 images (age bin 5 -> 44.5y)
[OK] Processed 1000 images (age bin 4 -> 34.5y)
[OK] Processed 1100 images (age bin 3 -> 24.5y)
[OK] Processed 1200 images (age bin 0 -> 1.0y)
[OK] Processed 1300 images (age bin 4 -> 34.5y)
[OK] Processed 1400 images (age bin 5 -> 44.5y)
[OK] Processed 1500 images (age bin 3 -> 24.5y)
[OK] Processed 1600 images (age bin 3 -> 24.5y)
[OK] Processed 1700 images (age bin 3 -> 24.5y)
[OK] Processed 1800 images (age bin 3 -> 24.5y)
[OK] Processed 1900 images (age bin 3 -> 24.5y)
[OK] Processed 2000 images (age bin 4 -> 34.5y)
[OK] Processed 2100 images (age bin 3 -> 24.5y)
[OK] Processed 2200 images (age bin 2 -> 14.5y)
[OK] Processed 2300 images (age bin 4 -> 34.5y)
[OK] Processed 2400 images (age bin 4 -> 34.5y)
[OK] Processed 2500 images (age bin 4 -> 34.5y)
[OK] Processed 2600 images (age bin 3 -> 24.5y)
[OK] Processed 2700 images (age bin 3 -> 24.5y)
[OK] Processed 2800 images (age bin 5 -> 44.5y)
[OK] Processed 2900 images (age bin 6 -> 54.5y)
[OK] Processed 3000 images (age bin 1 -> 6.0y)
[OK] Processed 3100 images (age bin 3 -> 24.5y)
[OK] Processed 3200 images (age bin 5 -> 44.5y)
[OK] Processed 3300 images (age bin 3 -> 24.5y)
[OK] Processed 3400 images (age bin 5 -> 44.5y)
[OK] Processed 3500 images (age bin 3 -> 24.5y)
[OK] Processed 3600 images (age bin 2 -> 14.5y)
[OK] Processed 3700 images (age bin 5 -> 44.5y)
[OK] Processed 3800 images (age bin 1 -> 6.0y)
[OK] Processed 3900 images (age bin 6 -> 54.5y)
[OK] Processed 4000 images (age bin 4 -> 34.5y)
[OK] Processed 4100 images (age bin 4 -> 34.5y)
[OK] Processed 4200 images (age bin 5 -> 44.5y)
[OK] Processed 4300 images (age bin 1 -> 6.0y)
[OK] Processed 4400 images (age bin 2 -> 14.5y)
[OK] Processed 4500 images (age bin 2 -> 14.5y)
[OK] Processed 4600 images (age bin 1 -> 6.0y)
[OK] Processed 4700 images (age bin 1 -> 6.0y)
[OK] Processed 4800 images (age bin 2 -> 14.5y)
[OK] Processed 4900 images (age bin 3 -> 24.5y)
[OK] Processed 5000 images (age bin 4 -> 34.5y)
C:\Users\miles\vcs\how-alike\scripts\train-age-probe-fairface.py:279: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.
  torch.onnx.export(
W1020 21:20:15.191856 12348 torch\onnx\_internal\exporter\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 14 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features
[OK] Extracted 5000 embeddings from FairFace

[OK] Dataset: 5000 samples
    Age range: 1.0-77.5
    Age mean: 29.4 +/- 16.1

[OK] Split: 4250 train, 750 val

[OK] Training age probe...
    Model params: 77,090 (~0.29 MB)
    Device: cpu
Epoch 1/100: train_mae=17.74 val_mae=11.86 lr=0.001000
Epoch 2/100: train_mae=10.56 val_mae=10.35 lr=0.001000
Epoch 3/100: train_mae=9.47 val_mae=9.74 lr=0.001000
Epoch 4/100: train_mae=9.04 val_mae=9.59 lr=0.001000
Epoch 5/100: train_mae=8.90 val_mae=9.30 lr=0.001000
Epoch 6/100: train_mae=8.51 val_mae=9.27 lr=0.001000
Epoch 7/100: train_mae=8.32 val_mae=9.07 lr=0.001000
Epoch 8/100: train_mae=8.15 val_mae=9.16 lr=0.001000
Epoch 9/100: train_mae=7.96 val_mae=8.96 lr=0.001000
Epoch 10/100: train_mae=7.67 val_mae=8.91 lr=0.001000
Epoch 11/100: train_mae=7.56 val_mae=8.83 lr=0.001000
Epoch 12/100: train_mae=7.44 val_mae=8.98 lr=0.001000
Epoch 13/100: train_mae=7.30 val_mae=8.85 lr=0.001000
Epoch 14/100: train_mae=7.12 val_mae=8.72 lr=0.001000
Epoch 15/100: train_mae=6.87 val_mae=8.76 lr=0.001000
Epoch 16/100: train_mae=6.89 val_mae=8.89 lr=0.001000
Epoch 17/100: train_mae=6.69 val_mae=8.75 lr=0.001000
Epoch 18/100: train_mae=6.58 val_mae=8.79 lr=0.001000
Epoch 19/100: train_mae=6.57 val_mae=8.73 lr=0.001000
Epoch 20/100: train_mae=6.36 val_mae=8.74 lr=0.000500
Epoch 21/100: train_mae=6.15 val_mae=8.73 lr=0.000500
Epoch 22/100: train_mae=5.99 val_mae=8.80 lr=0.000500
Epoch 23/100: train_mae=5.96 val_mae=8.59 lr=0.000500
Epoch 24/100: train_mae=5.84 val_mae=8.61 lr=0.000500
Epoch 25/100: train_mae=5.80 val_mae=8.76 lr=0.000500
Epoch 26/100: train_mae=5.75 val_mae=8.62 lr=0.000500
Epoch 27/100: train_mae=5.73 val_mae=8.69 lr=0.000500
Epoch 28/100: train_mae=5.66 val_mae=8.65 lr=0.000500
Epoch 29/100: train_mae=5.53 val_mae=8.71 lr=0.000250
Epoch 30/100: train_mae=5.42 val_mae=8.70 lr=0.000250
Epoch 31/100: train_mae=5.43 val_mae=8.72 lr=0.000250
Epoch 32/100: train_mae=5.38 val_mae=8.62 lr=0.000250
Epoch 33/100: train_mae=5.35 val_mae=8.68 lr=0.000250
[OK] Early stopping at epoch 33

[OK] Exporting to ONNX...
[torch.onnx] Obtain model graph for `AgeProbe([...]` with `torch.export.export(..., strict=False)`...
[torch.onnx] Traceback (most recent call last):
  File "C:\Users\miles\vcs\how-alike\scripts\train-age-probe-fairface.py", line 345, in <module>
    export_to_onnx(model)
  File "C:\Users\miles\vcs\how-alike\scripts\train-age-probe-fairface.py", line 279, in export_to_onnx
    torch.onnx.export(
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\__init__.py", line 296, in export
    return _compat.export_compat(
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\_internal\exporter\_compat.py", line 143, in export_compat
    onnx_program = _core.export(
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\_internal\exporter\_flags.py", line 23, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\_internal\exporter\_core.py", line 1336, in export
    result = strategy(model, args, kwargs, dynamic_shapes=dynamic_shapes)
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\_internal\exporter\_capture_strategies.py", line 126, in __call__
    self._success(model)
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\_internal\exporter\_capture_strategies.py", line 238, in _success
    self._verbose_print(
  File "C:\Users\miles\AppData\Roaming\Python\Python310\site-packages\torch\onnx\_internal\exporter\_capture_strategies.py", line 29, in <lambda>
    return lambda *args, **kwargs: print("[torch.onnx]", *args, **kwargs)
  File "C:\Python310\lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\u2705' in position 89: character maps to <undefined>
